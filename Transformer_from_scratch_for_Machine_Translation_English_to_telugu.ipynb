{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGt5Ekt81iq9"
      },
      "source": [
        "# Transfomer from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3rvMRohg9AH",
        "outputId": "14dc137c-7e9e-4145-8c1a-07337685855c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bertviz) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.11.0+cu113)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.24.27)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from bertviz) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bertviz) (2.23.0)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.20.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (4.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.12.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.27 in /usr/local/lib/python3.7/dist-packages (from boto3->bertviz) (1.27.27)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.27->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.27->boto3->bertviz) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.27->boto3->bertviz) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.0->bertviz) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install tokenizers transformers\n",
        "!pip install tqdm\n",
        "! pip install bertviz\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.models import BPE\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import RobertaTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os \n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch \n",
        "\n",
        "from torch.nn import functional as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Au9KnljxrZ4",
        "outputId": "6b50b51b-780c-4fc7-9347-0befcaff511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTe6b9dbofCO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import torch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc-buo75v-jL"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/dataset/language.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcKy-dOyv_ym"
      },
      "outputs": [],
      "source": [
        "data['English'].to_csv(\"english.txt\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9VYjtvlomCc"
      },
      "outputs": [],
      "source": [
        "tokenizer_english=ByteLevelBPETokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_OUb4ylooKr"
      },
      "outputs": [],
      "source": [
        "tokenizer_english.train(['english.txt'],vocab_size=50000,min_frequency=2,special_tokens=['<s>','<pad>','</s>',',<unk>','<mask>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwBvKraihQ1F",
        "outputId": "56e1ca61-b3c0-4643-f334-4b0b7174e0c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=4, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tokenizer_english.encode(\"Hi how are you\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LktgmL2TxMqL"
      },
      "outputs": [],
      "source": [
        "data['Telugu'].to_csv(\"telugu.txt\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pmEBfCsxX04"
      },
      "outputs": [],
      "source": [
        "tokenizer_telugu=ByteLevelBPETokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmwuS7eVxb9Q"
      },
      "outputs": [],
      "source": [
        "tokenizer_telugu.train(['telugu.txt'],vocab_size=50000,min_frequency=3,special_tokens=['<s>','<pad>','</s>',',<unk>','<mask>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98aR7jb71qR5"
      },
      "source": [
        "# Position embedding and embedding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkCydVCe1zSD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import  torch.nn as nn\n",
        "import tensorflow as tf\n",
        "import  pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self,vocab_size,embed_dim):\n",
        "        super(Embedding,self).__init__()\n",
        "        self.embedd=nn.Embedding(vocab_size,embed_dim)\n",
        "     \n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        out=self.embedd(x)\n",
        "        return out\n",
        "\n",
        "class PositionEmbedding(nn.Module):\n",
        "    def __init__(self,max_sen=5000,dim_data=512):\n",
        "        super(PositionEmbedding,self).__init__()\n",
        "        self.dim=dim_data\n",
        "\n",
        "        pos=torch.zeros(max_sen,dim_data)\n",
        "\n",
        "        for x in range(max_sen):\n",
        "            for y in range(0,dim_data,2):\n",
        "\n",
        "                pos[x,y]=math.sin(x/(1000**(2*y/self.dim)))\n",
        "                pos[x,y+1]=math.cos(x/(1000**((2*(y+1))/self.dim)))\n",
        "\n",
        "\n",
        "        pos=torch.unsqueeze(pos,0)\n",
        "        self.register_buffer('pe',pos)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        # The reason we increase the embedding values before addition is to make the positional encoding relatively smaller. This means the original meaning in the embedding vector won’t be lost when we add them together.\n",
        "\n",
        "        x=x*math.sqrt(self.dim)\n",
        "        sequnence_lenght=x.size(1) # Batch_size , sequence_length , dimensions\n",
        "  \n",
        "\n",
        "        output=x+torch.autograd.Variable(self.pe[:,:sequnence_lenght],requires_grad=False)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjJ9_0hJ14x3"
      },
      "source": [
        "# Multi head attention block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bCMUJVT1-xg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import  torch.nn as nn\n",
        "import  torch\n",
        "import  torch.nn.functional as F\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import  pandas as pd\n",
        "\n",
        "class  MultiHeadattention(nn.Module):\n",
        "    def __init__(self,n_heads=8,dim=512):\n",
        "\n",
        "        super(MultiHeadattention,self).__init__()\n",
        "        self.size_of_matrix=int(dim/n_heads)\n",
        "        self.n_heads=n_heads\n",
        "        self.key=nn.Linear(dim,dim,bias=False)\n",
        "        self.query=nn.Linear(dim,dim,bias=False)\n",
        "        self.value=nn.Linear(dim,dim,bias=False)\n",
        "        self.out=nn.Linear(n_heads*self.size_of_matrix,dim)\n",
        "        self.droput=nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self,key,value,query,mask=None):\n",
        "      \n",
        "\n",
        "    \n",
        "\n",
        "       \n",
        "      \n",
        "        batch_size=key.size(0)\n",
        "        seq_lenght=key.size(1)\n",
        "\n",
        "        batch_size_query=query.size(0)\n",
        "        batch_lenght_query=query.size(1)\n",
        "\n",
        "        key=self.key(key)\n",
        "        value=self.value(value)\n",
        "        query=self.query(query)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        key=key.view(batch_size,seq_lenght,self.n_heads,self.size_of_matrix)\n",
        "\n",
        "        value =value.view(batch_size, seq_lenght, self.n_heads, self.size_of_matrix)\n",
        "\n",
        "        query = query.view( batch_size_query, batch_lenght_query, self.n_heads, self.size_of_matrix)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # key=self.key(key) #\n",
        "        # query=self.query(query)\n",
        "        # value=self.value(value)\n",
        "\n",
        "     \n",
        "\n",
        "        key=key.transpose(1,2) # Transpose will convert it into batch_size , n_heads , seq_length , size_of_matrix\n",
        "        query=query.transpose(1,2)\n",
        "        value=value.transpose(1,2)\n",
        "\n",
        "        # convert the query matrix into the batch_size , n_heads, size_of_matrix , seq_lenght\n",
        "\n",
        "      \n",
        "        scalar_output=torch.matmul(query,key.transpose(-2,-1))\n",
        "\n",
        "        scalar_output_square_root=scalar_output/math.sqrt(self.size_of_matrix)\n",
        "      \n",
        "\n",
        "        \n",
        "\n",
        "    \n",
        "        if mask is not None:\n",
        "            mask=mask.unsqueeze(1)\n",
        "   \n",
        "           \n",
        "            scalar_output_square_root=scalar_output_square_root.masked_fill(mask==0,float('-inf'))  \n",
        "\n",
        "\n",
        "        output_from_softmax=F.softmax(scalar_output_square_root,dim=-1)\n",
        "\n",
        "\n",
        "        mutliplication_with_value=torch.matmul(self.droput(output_from_softmax),value)\n",
        "\n",
        "        \n",
        "\n",
        "        concat=mutliplication_with_value.transpose(1,2).contiguous().view(batch_size, -1 ,self.n_heads*self.size_of_matrix)\n",
        "\n",
        "        outout_from_multihead=self.out(concat)\n",
        "\n",
        "        return outout_from_multihead , output_from_softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfrqVn232GGD"
      },
      "source": [
        "# EncoderBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO_ZkwneLyZX"
      },
      "outputs": [],
      "source": [
        "class Encoderlayer(nn.Module):\n",
        "    def __init__(self,dim,expansion_factor,num_heads=8):\n",
        "\n",
        "        super(Encoderlayer,self).__init__()\n",
        "        self.attn=MultiHeadattention(num_heads,dim)\n",
        "        self.droput=nn.Dropout(0.2) \n",
        "        self.Layernorm1=nn.LayerNorm(dim)\n",
        "        self.Layernorm2=nn.LayerNorm(dim)\n",
        "        self.feedwordnetwork=nn.Sequential(\n",
        "            nn.Linear( dim, expansion_factor*dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim*expansion_factor,dim)\n",
        "        )\n",
        "\n",
        "    def forward(self,x,mask=None):\n",
        "       \n",
        "        x1,att_prob=self.attn(x,x,x,mask)\n",
        "        x=self.Layernorm1(self.droput(x1)+x)\n",
        "        x1=self.feedwordnetwork(x)\n",
        "        x=self.Layernorm2(self.droput(x1)+x)\n",
        "        return x,att_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E613KaJq2Lyg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self,src_lenght,expansion_factor,dim=512,num_heads=8,max_sequence_lenght=5000):\n",
        "\n",
        "        super(TransformerEncoderBlock,self).__init__()\n",
        "\n",
        "        self.Embedding=Embedding(src_lenght,dim)\n",
        "        self.num_layers=6\n",
        "        self.positionEmbedding=PositionEmbedding(max_sen=max_sequence_lenght,dim_data=dim)\n",
        "        self.layers = nn.ModuleList([\n",
        "            Encoderlayer(dim,expansion_factor)\n",
        "            for _ in range(self.num_layers)\n",
        "        ])\n",
        "    \n",
        "    def forward(self,x,mask):\n",
        "        embeded_out = self.Embedding(x)\n",
        "        \n",
        "        x= self.positionEmbedding(embeded_out)\n",
        " \n",
        "\n",
        "        for layer in self.layers:\n",
        "            x,attn_prob=layer(x,mask)\n",
        "            \n",
        "            \n",
        "        return x,attn_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9pMUveR2TZA"
      },
      "source": [
        "# DecoderBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKFnzsC0PrYH"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self,expansion_factor,dim=512,num_heads=8):\n",
        "        super(DecoderLayer,self).__init__()\n",
        "        self.attn=MultiHeadattention(num_heads,dim)\n",
        "        self.attn2=MultiHeadattention(num_heads,dim)\n",
        "        self.n_layers=6\n",
        "        self.dropout_1=nn.Dropout(0.2)\n",
        "        self.Layer_1=nn.LayerNorm(dim)\n",
        "       \n",
        "        self.feedforward_network=nn.Sequential(\n",
        "\n",
        "            nn.Linear(dim,dim*expansion_factor),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim*expansion_factor , dim\n",
        "                      )\n",
        "        )\n",
        "\n",
        "    def forward(self,x,encoder_out,target_mask,src_mask):\n",
        "\n",
        "        x1,_=self.attn(x,x,x,target_mask)\n",
        "            # picking value from encoder outpout\n",
        "\n",
        "        x2=self.Layer_1(self.dropout_1(x1)+x)\n",
        "\n",
        "        x,attn_prob= self.attn2(encoder_out,encoder_out,x2,src_mask)\n",
        "\n",
        "        x = self.Layer_1(self.dropout_1(x2) + x)\n",
        "\n",
        "        x1=self.feedforward_network(x)\n",
        "        x=self.Layer_1(self.dropout_1(x1)+x)\n",
        "\n",
        "        return x,attn_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AJy1OtR2ZuX"
      },
      "outputs": [],
      "source": [
        "import  torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    def __init__(self,target_vocab_size,expansion_factor,dim=512,max_sequence_length=5000,num_heads=8):\n",
        "        super(TransformerDecoderBlock,self).__init__()\n",
        "        self.embedding=Embedding(target_vocab_size,dim)\n",
        "        self.position_embedding=PositionEmbedding(max_sen=max_sequence_length,dim_data=dim)\n",
        "        self.dropout_1=nn.Dropout(0.2)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(expansion_factor)\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "\n",
        "    def forward(self,x,encoder_output,masked_target,src_mask):\n",
        "      \n",
        "        embedded_vector=self.embedding(x)\n",
        "        position=self.position_embedding(embedded_vector)\n",
        "        x=self.dropout_1(position)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x,attn_prob=layer(x,encoder_output,masked_target,src_mask)\n",
        "\n",
        "        return x,attn_prob     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQWZeX92fFn"
      },
      "source": [
        "# Transformer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEfbzWNk2lQ3"
      },
      "outputs": [],
      "source": [
        "import  torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self,vocab_size_source,vocab_size_target,dim,expansion_factor,DEVICE):\n",
        "        \n",
        "        super(TransformerModel, self).__init__()\n",
        "        \n",
        "        self.encoder=TransformerEncoderBlock(vocab_size_source,expansion_factor)\n",
        "       \n",
        "        self.decoder=TransformerDecoderBlock(vocab_size_target,expansion_factor)\n",
        "\n",
        "        self.logits=nn.Linear(dim,vocab_size_target)\n",
        "\n",
        "    def mask_target(self,target):\n",
        "        batch_size , seq_lenght = target.size(0),target.size(1)\n",
        "\n",
        "        masked_target = torch.tril(torch.ones(seq_lenght,seq_lenght)).expand(1,seq_lenght,seq_lenght)\n",
        "\n",
        "        # return masked_target.to(DEVICE,dtype=torch.long)\n",
        "        return  masked_target.to(DEVICE,dtype=torch.int64)\n",
        "\n",
        "    def pad_mask(self,x,idx=1) :\n",
        "\n",
        "        # This masking helps not to consider the indexes for training the padded values \n",
        "\n",
        "       mask=(x!=1).unsqueeze(-2)\n",
        "\n",
        "       return mask.to(DEVICE)\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self,x,y):\n",
        "        # source mask \n",
        "        src_mask=self.pad_mask(x).to(DEVICE)\n",
        "       \n",
        "        encoder_output,_=self.encoder(x,src_mask)\n",
        "      \n",
        "        masked_target= torch.bitwise_and(self.pad_mask(y) ,self.mask_target(y) )\n",
        "\n",
        "      \n",
        "   \n",
        "     \n",
        "        decoder_output,attent_prob=self.decoder(y,encoder_output,masked_target,src_mask)\n",
        "       \n",
        "        output=self.logits(decoder_output)\n",
        "        probs_output=F.log_softmax(output,-1)\n",
        "\n",
        "        return probs_output\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHhhBPSY4W5D"
      },
      "source": [
        "# Creating English & Telugu dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nx3nHJj2X77"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6G7Ozmeg3cs"
      },
      "outputs": [],
      "source": [
        "class EnglishtoTeluguDataset:\n",
        "    def __init__(self,english,telugu,tokenizer_te,tokenizer_en,max_length=60):\n",
        "        self.english=english\n",
        "        self.telugu=telugu\n",
        "        self.max_len_en=max_length-1\n",
        "        self.max_len_te=max_length \n",
        "        self.tokenizer_en=tokenizer_en\n",
        "        self.tokenizer_te=tokenizer_te\n",
        "    def __len__(self):\n",
        "        return len(self.english)\n",
        "    def __getitem__(self,item):\n",
        "        english = self.tokenizer_en.encode(self.english[item]).ids\n",
        "        telugu  = self.tokenizer_te.encode(self.telugu[item]).ids\n",
        "\n",
        "        # english adding start ane end of the sentnece \n",
        "     \n",
        "        if len(english) > self.max_len_en-2:\n",
        "          english=[0]+english[:self.max_len_en-2]+[2]\n",
        "        else:\n",
        "          english=[0]+english+[2]\n",
        "\n",
        "        if len(english) < self.max_len_en:\n",
        "          english =english + [1]*(self.max_len_en-len(english))\n",
        " \n",
        "\n",
        "\n",
        "        if len(telugu) > self.max_len_te-2:\n",
        "          telugu=[0]+telugu[:self.max_len_te-2]+[2]\n",
        "        else:\n",
        "          telugu=[0]+telugu+[2]\n",
        "\n",
        "        if len(telugu) < self.max_len_te:\n",
        "          telugu = telugu + [1]*(self.max_len_te-len(telugu))\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "        return {\n",
        "\n",
        "            \"src\":torch.tensor(english,dtype=torch.long),\n",
        "            \"targted\":torch.tensor(telugu,dtype=torch.long)\n",
        "\n",
        "\n",
        "        }   \n",
        "      \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G8eWhTSHBfV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYN_OvZS1ETN"
      },
      "outputs": [],
      "source": [
        "def loss_fn(output,target):\n",
        "    loss_cal=nn.CrossEntropyLoss(ignore_index=1)\n",
        "    loss=loss_cal(output,target)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSaoP74_SmhQ"
      },
      "outputs": [],
      "source": [
        "def covert_id_to_text(ids,tokenize,eos_indx):\n",
        "\n",
        "    if ids.dim()==1:\n",
        "      \n",
        "        output_tokens=[]\n",
        "        for token_ids in ids:\n",
        "            data_list=[]\n",
        "            data_list.append(token_ids)\n",
        "         \n",
        "          \n",
        "            if int(token_ids)==eos_indx:\n",
        "                break\n",
        "            else:\n",
        "              output_tokens.append(tokenize.decode(data_list).strip())       \n",
        "        return output_tokens        \n",
        "    elif ids.dim()==2 :\n",
        "        return [covert_id_to_text(ids[i, :], tokenize,eos_indx) for i in range(ids.size(0))]\n",
        "\n",
        "    raise RuntimeError(f' The dimesion should be 2 but we received {ids.dim()} ')    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU_TWH_iRBbD"
      },
      "outputs": [],
      "source": [
        "actul=[]\n",
        "pred=[]\n",
        "import pickle \n",
        "def eval_fn(val_data, model):\n",
        "    model.eval()\n",
        "    total_loss=0\n",
        "    steps=0\n",
        "    hypotheses = []\n",
        "    references = []\n",
        "    with torch.no_grad():\n",
        "        tk = tqdm(val_data, total=len(val_data)) \n",
        "        for batch_size , data in enumerate(tk):\n",
        "            src=data['src']\n",
        "            target=data['targted']\n",
        "\n",
        "            src=src.to(DEVICE, dtype=torch.long)\n",
        "            target=target.to(DEVICE,dtype=torch.long)\n",
        "\n",
        "            output=model(src,target[:,:-1])\n",
        "            \n",
        "            \n",
        "            loss=loss_fn(output.view(-1,output.size(-1)),target[:,1:].contiguous().view(-1))\n",
        "\n",
        "            total_loss+=loss.item()\n",
        "\n",
        "            steps=+1\n",
        "\n",
        "            output = output.argmax(dim=-1)\n",
        "\n",
        "            target=target[:,1:]\n",
        "\n",
        "            # Calculating belu score \n",
        "            pred_tokens=covert_id_to_text(output,tokenizer_telugu,2)\n",
        "\n",
        "            actual_tokens=covert_id_to_text(target,tokenizer_telugu,2)\n",
        "\n",
        "\n",
        "            hypotheses += pred_tokens\n",
        "         \n",
        "       \n",
        "            references += [[token] for token in  actual_tokens]\n",
        "\n",
        "  \n",
        "    actul.append(actual_tokens)\n",
        "    pred.append(pred_tokens)\n",
        "    perplexity = np.log(total_loss / len(val_data))\n",
        "  \n",
        "    bleu_data = bleu_score(hypotheses, references)\n",
        "      \n",
        "\n",
        "    return bleu_data,perplexity\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFnyitb5_TZ5"
      },
      "outputs": [],
      "source": [
        "def train_fn(train_data,model,optimizer,clip=1.0,scheduler=None):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    step=0\n",
        "    tk = tqdm(train_data, total=len(train_data)) \n",
        "\n",
        "    for batch_size , train_data in enumerate(tk):\n",
        "\n",
        "       \n",
        "        src=train_data['src']\n",
        "        target=train_data['targted']\n",
        "\n",
        "        src=src.to(DEVICE, dtype=torch.long)\n",
        "        target=target.to(DEVICE,dtype=torch.long)\n",
        "\n",
        "       # forward pass \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output=model(src,target[:,:-1])\n",
        "\n",
        "       \n",
        "        \n",
        "        loss=loss_fn(output.view(-1,output.size(-1)),target[:,1:].contiguous().view(-1)) # \n",
        "\n",
        "\n",
        "\n",
        "        total_loss+=loss.item()\n",
        "\n",
        "        steps=+1\n",
        "\n",
        "        output = output.argmax(dim=-1)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # tdqm.set_postfix(loss=total_loss/steps)\n",
        "\n",
        "\n",
        "\n",
        "        perplexity = np.log(total_loss / len(train_data))\n",
        "\n",
        "\n",
        "\n",
        "    return output ,perplexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK1vVGByyr_Z"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "\n",
        "    df_train , df_valid= train_test_split(data,test_size=0.3, random_state=42)\n",
        "    df_train=df_train.reset_index(drop=True)\n",
        "    df_valid=df_valid.reset_index(drop=True)\n",
        "\n",
        "    train_data=EnglishtoTeluguDataset(\n",
        "    english=df_train.English.values,\n",
        "    telugu=df_train.Telugu.values,\n",
        "    tokenizer_te=tokenizer_telugu,\n",
        "    tokenizer_en=tokenizer_english\n",
        "    )\n",
        "\n",
        "    \n",
        "\n",
        "    train_data_loader=torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=128\n",
        "     )\n",
        "    \n",
        "\n",
        "\n",
        "    val_data=EnglishtoTeluguDataset(\n",
        "     english=df_valid.English.values,\n",
        "     telugu=df_valid.Telugu.values,\n",
        "    tokenizer_te=tokenizer_telugu,\n",
        "    tokenizer_en=tokenizer_english\n",
        "    \n",
        "\n",
        "     )\n",
        "  \n",
        "    validation_data_loader=torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=128\n",
        "    )\n",
        "\n",
        "  \n",
        "\n",
        "    num_train_steps = int(len(train_data) /128)* 15\n",
        "\n",
        "    param_optimizer = list(model.parameters())\n",
        "\n",
        "    # print(param_optimizer)\n",
        "    \n",
        "  \n",
        "    optimizer = AdamW( param_optimizer, lr=1e-4)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, \n",
        "        num_warmup_steps=0, \n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_bleu4 = float('-inf')\n",
        "    es_patience = 3\n",
        "    patience = 0 \n",
        "    model_path = '/content/drive/MyDrive/Model/model.pth'\n",
        "\n",
        "    for i in range(15):\n",
        "        print(\"Epoch {}/{}\".format(i+1,15))\n",
        "\n",
        "        _ , train_prexlity=train_fn(train_data_loader,model,optimizer,clip=1.0,scheduler=scheduler)\n",
        "        blue_score,test_prexlity = eval_fn( validation_data_loader,model)\n",
        "\n",
        "  \n",
        "    \n",
        "      \n",
        "        print(f'Epoch :{i+1} and  train prexlity {train_prexlity:.4f}')\n",
        "\n",
        "        print(f'Epoch :{i+1} and  test prexlity {test_prexlity:.4f} and belu score on validation is {blue_score}')\n",
        "\n",
        "        is_best = blue_score > best_bleu4\n",
        "        if is_best:\n",
        "            print(f'BLEU score improved ({best_bleu4:.4f} -> {blue_score:.4f}). Saving Model!')\n",
        "            best_bleu4 = blue_score\n",
        "            patience = 0\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        else:\n",
        "            patience += 1\n",
        "            print(f'Early stopping counter: {patience} out of {es_patience}')\n",
        "            if patience == es_patience:\n",
        "                print(f'Early stopping! Best BLEU4: {best_bleu4:.4f}')\n",
        "                break\n",
        "       \n",
        "       \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXdujr6ZIMK9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3lYwORR38o2"
      },
      "outputs": [],
      "source": [
        "run()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Inference"
      ],
      "metadata": {
        "id": "-rvVfJCovw42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "INPUT_SIZE=tokenizer_english.get_vocab_size()\n",
        "OUTPUT_SIZE=tokenizer_telugu.get_vocab_size()\n",
        "\n",
        "\n",
        "DEVICE=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model=TransformerModel(INPUT_SIZE,OUTPUT_SIZE,512,3,DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Model/model.pth',map_location=DEVICE))\n",
        "# reloading the model \n",
        "\n",
        "model.to(DEVICE)\n"
      ],
      "metadata": {
        "id": "Foozht20q5m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr , df_val = train_test_split(data,test_size=0.3, random_state=42)\n",
        "df_tr=df_tr.reset_index(drop=True)\n",
        "df_val=df_val.reset_index(drop=True)\n",
        "\n",
        "train_data=EnglishtoTeluguDataset(\n",
        "    english=df_tr.English.values,\n",
        "    telugu=df_tr.Telugu.values,\n",
        "   tokenizer_te=tokenizer_telugu,\n",
        "    tokenizer_en=tokenizer_english\n",
        "    )\n",
        "\n",
        "train_data_loader=torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=256\n",
        "     )\n",
        "\n",
        "val_data=EnglishtoTeluguDataset(\n",
        "     english=df_val.English.values,\n",
        "     telugu=df_val.Telugu.values,\n",
        "   tokenizer_te=tokenizer_telugu,\n",
        "    tokenizer_en=tokenizer_english\n",
        "    \n",
        "    )\n",
        "validation_data_loader=torch.utils.data.DataLoader(\n",
        "    val_data,\n",
        "    batch_size=256\n",
        "    )\n"
      ],
      "metadata": {
        "id": "r1FfEdadqvuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing_function(model,src,DEVICE):\n",
        "    model.eval()\n",
        "\n",
        "    target_ids=[]\n",
        "\n",
        "   \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        src_mask=model.pad_mask(src).to(DEVICE)\n",
        "        src=src.unsqueeze(0).to(DEVICE)\n",
        "          \n",
        "        # calling encoder to get encoder_output\n",
        "        # get paded mask for input\n",
        "      \n",
        "        with torch.no_grad():\n",
        "            encoder_output,encoder_attention=model.encoder(src,src_mask)\n",
        "\n",
        "        target_ids=[0]\n",
        "\n",
        "        for x in range(60):\n",
        "             target_id=None\n",
        "            \n",
        "             target = torch.tensor(target_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)# (1, target_seq_len)\n",
        "          \n",
        "             masked_target= torch.bitwise_and(model.pad_mask(target) ,model.mask_target(target)) \n",
        "\n",
        "             with torch.no_grad():\n",
        "                 decoder_output,attn=model.decoder(target,encoder_output,masked_target,src_mask)\n",
        "                 output_logits=model.logits(decoder_output)\n",
        "                \n",
        "                 output=F.log_softmax(output_logits,dim=-1)\n",
        "\n",
        "                 target_id = output.argmax(dim=-1)[:, -1].item()\n",
        "               \n",
        "                \n",
        "                 target_ids.append(target_id)\n",
        "                 if target_id==2:\n",
        "                   break\n",
        "                  \n",
        "        return   target_ids ,attn.squeeze(0).cpu().detach().numpy() , encoder_attention.squeeze(0).cpu().detach().numpy()\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "rp1ykerzq0A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15 \n",
        "src=val_data.__getitem__(157)['src']\n",
        "target_data=val_data.__getitem__(157)['targted']\n",
        "\n",
        "tokenizer_telugu.decode(target_data.cpu().detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "cGykEBevyJSy",
        "outputId": "9445fee2-16b3-4215-92d6-b7f7d530b99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'హైదరాబాదు నగరంలో 2003లో మల్టీ మోడల్ రవాణా వ్యవస్థను మొదలు పెట్టారు.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_english.decode(src.cpu().detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "cTTn17NZyWZL",
        "outputId": "0937dade-83fa-487a-8eac-0fc5b0b4c1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Multi model transportation system was started in Hyderabad in 2003.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output,decoder_attent,encoder_atten=testing_function(model,src,DEVICE)"
      ],
      "metadata": {
        "id": "HYs2ph7Vv7TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target=[]\n",
        "for x in output:\n",
        "\n",
        "  data_list=[]\n",
        "  data_list.append(x)\n",
        "  target.append(tokenizer_telugu.decode(data_list))"
      ],
      "metadata": {
        "id": "teezynUWJ6Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( f' Input to transformer : {tokenizer_english.decode(src.cpu().detach().numpy())}')\n",
        "print(f' Actual target : {tokenizer_telugu.decode(target_data.cpu().detach().numpy())}')\n",
        "print(f'Predicted target : {tokenizer_telugu.decode(output)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TbPTJCRv823",
        "outputId": "10b67a1a-ada0-44f2-ea36-d201b3355041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input to transformer : Multi model transportation system was started in Hyderabad in 2003.\n",
            "\n",
            " Actual target : హైదరాబాదు నగరంలో 2003లో మల్టీ మోడల్ రవాణా వ్యవస్థను మొదలు పెట్టారు.\n",
            "\n",
            "Predicted target : హైదరాబాదు నగరంలో 2003లో 2003లో మోడల్ రవాణా వ్యవస్థ పెట్టు మొదలైంది.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Transformer from scratch for Machine Translation - English to telugu.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}